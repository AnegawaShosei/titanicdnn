{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5223fcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Try: pd.DataFrame.to_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "c5c5a2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting index for easier usage\n",
    "train = pd.read_csv(\"train.csv\").set_index(\"PassengerId\")\n",
    "test = pd.read_csv(\"test.csv\").set_index(\"PassengerId\")\n",
    "\n",
    "train = train.drop(\"Cabin\", axis = 1)\n",
    "test = test.drop(\"Cabin\", axis = 1)\n",
    "\n",
    "\n",
    "#Dropping cabin column as a whole and also removing rows that are missing an Age value\n",
    "# train = train[train.Age.notnull()].drop(\"Cabin\", axis = 1)\n",
    "# test = test[test.Age.notnull()].drop(\"Cabin\", axis = 1)\n",
    "\n",
    "#Filling the two missing values in Embarked that I found on google\n",
    "train.Embarked = train.Embarked.fillna(\"S\")\n",
    "\n",
    "#Removing ticket prefix,replacing the special value of ticket and then converting all to floats\n",
    "train.Ticket = train.Ticket.map(lambda t : t.split()[-1]).replace(\"LINE\", -1).astype(\"float\")\n",
    "test.Ticket = test.Ticket.map(lambda t : t.split()[-1]).replace(\"LINE\", -1).astype(\"float\")\n",
    "\n",
    "#Replacing each value of Embarked with a respective integer\n",
    "# train.Embarked = train.Embarked.replace(\"S\", 1).replace(\"Q\", 2).replace(\"C\", 3)\n",
    "# test.Embarked = test.Embarked.replace(\"S\", 1).replace(\"Q\", 2).replace(\"C\", 3)\n",
    "\n",
    "#Same with sex\n",
    "train.Sex = train.Sex.replace(\"male\", 1).replace(\"female\", 0)\n",
    "test.Sex = test.Sex.replace(\"male\", 1).replace(\"female\", 0)\n",
    "\n",
    "dummies = pd.get_dummies(train.Pclass, prefix = \"class\")\n",
    "dummies_embark = pd.get_dummies(train.Embarked, prefix = \"loc\")\n",
    "train = pd.concat([train, dummies, dummies_embark], axis = 1).drop(\"Pclass\", axis = 1).drop(\"Embarked\", axis = 1)\n",
    "\n",
    "dummies = pd.get_dummies(test.Pclass, prefix = \"class\")\n",
    "dummies_embark = pd.get_dummies(test.Embarked, prefix = \"loc\")\n",
    "test = pd.concat([test, dummies, dummies_embark], axis = 1).drop(\"Pclass\", axis = 1).drop(\"Embarked\", axis = 1)\n",
    "\n",
    "#Replacing titles with dummy\n",
    "def get_title(name):\n",
    "    if '.' in name:\n",
    "        return name.split(',')[1].split('.')[0].strip()\n",
    "    else:\n",
    "        return 'Unknown'\n",
    "\n",
    "def replace_titles(x):\n",
    "    title = x['Title']\n",
    "    if title in ['Capt', 'Col', 'Don', 'Jonkheer', 'Major', 'Rev', 'Sir']:\n",
    "        return 'Mr'\n",
    "    elif title in ['the Countess', 'Mme', 'Lady']:\n",
    "        return 'Mrs'\n",
    "    elif title in ['Mlle', 'Ms']:\n",
    "        return 'Miss'\n",
    "    elif title =='Dr':\n",
    "        if x['Sex']=='male':\n",
    "            return 'Mr'\n",
    "        else:\n",
    "            return 'Mrs'\n",
    "    else:\n",
    "        return title\n",
    "    \n",
    "train['Title'] = train['Name'].map(lambda x: get_title(x))\n",
    "train['Title'] = train.apply(replace_titles, axis=1)\n",
    "\n",
    "test['Title'] = test['Name'].map(lambda x: get_title(x))\n",
    "test['Title'] = test.apply(replace_titles, axis=1)\n",
    "\n",
    "dummies = pd.get_dummies(train.Title)\n",
    "test_dummies = pd.get_dummies(test.Title)\n",
    "\n",
    "train = pd.concat([train, dummies], axis = 1).drop(\"Name\", axis = 1).drop(\"Title\", axis = 1)\n",
    "test = pd.concat([test, test_dummies], axis =1).drop(\"Name\", axis = 1).drop(\"Title\", axis = 1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "ticket = train.Ticket.to_numpy().reshape(-1, 1)\n",
    "fare = train.Fare.to_numpy().reshape(-1, 1)\n",
    "age = train.Age.to_numpy().reshape(-1, 1)\n",
    "\n",
    "train.Ticket = scaler.fit_transform(ticket)\n",
    "train.Fare = scaler.fit_transform(fare)\n",
    "train.Age = scaler.fit_transform(age)\n",
    "\n",
    "ticket = test.Ticket.to_numpy().reshape(-1, 1)\n",
    "fare = test.Fare.to_numpy().reshape(-1, 1)\n",
    "age = test.Age.to_numpy().reshape(-1, 1)\n",
    "\n",
    "test.Ticket = scaler.fit_transform(ticket)\n",
    "test.Fare = scaler.fit_transform(fare)\n",
    "test.Age = scaler.fit_transform(age)\n",
    "\n",
    "#Dealing with missing ages\n",
    "train_na = train[train.Age.isnull()].fillna(train.mean())\n",
    "train = train[train.Age.notnull()]\n",
    "\n",
    "test.Age = test.Age.fillna(test.Age.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "61829f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Ticket\", \"Fare\", \"class_1\", \"class_2\", \"class_3\", \"loc_C\", \"loc_Q\", \"loc_S\", \"Master\", \"Miss\", \"Mr\", \"Mrs\"]\n",
    "\n",
    "#Converting the features to numpy arrays\n",
    "X = train[features].to_numpy()\n",
    "X_na = train_na[features].to_numpy()\n",
    "X_test = test[features].to_numpy().transpose()\n",
    "\n",
    "X_test = X_test.T\n",
    "\n",
    "#Same with Y\n",
    "Y = train[\"Survived\"].to_numpy()\n",
    "Y_na = train_na[\"Survived\"].to_numpy()\n",
    "Y = Y.reshape((Y.shape[0], 1))\n",
    "Y_na = Y_na.reshape((Y_na.shape[0], 1))\n",
    "\n",
    "\n",
    "#Splitting into 80-20 train dev split\n",
    "#TODO: MANUALLY SPLIT, MAKE THE AVG AGE DISTRIBUTION BE IN \n",
    "#X, X_dev, Y, Y_dev = train_test_split(X, Y, test_size = 0.20)\n",
    "\n",
    "len_dev = int(0.20 * (len(train) + len(train_na_fills)) // 1)\n",
    "\n",
    "X_train = X[:-len_dev, :]\n",
    "X_dev = X[-len_dev:, :]\n",
    "\n",
    "Y_train = Y[:-len_dev, :]\n",
    "Y_dev = Y[-len_dev:, :]\n",
    "\n",
    "Y = np.concatenate([Y_na, Y_train], axis = 0)\n",
    "X = np.concatenate([X_na, X_train], axis = 0)\n",
    "\n",
    "\n",
    "\n",
    "#Transposing all so they have correct dimentions\n",
    "X = X.astype(\"float32\")\n",
    "X_dev = X_dev.astype(\"float32\")\n",
    "Y = Y.astype(\"float32\")\n",
    "Y_dev = Y_dev.astype(\"float32\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "c9bad0fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6517 - accuracy: 0.7588\n",
      "Epoch 2/50\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6307 - accuracy: 0.8065\n",
      "Epoch 3/50\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6235 - accuracy: 0.8163\n",
      "Epoch 4/50\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6198 - accuracy: 0.8317\n",
      "Epoch 5/50\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 0.6175 - accuracy: 0.8387\n",
      "Epoch 6/50\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 0.6170 - accuracy: 0.8387\n",
      "Epoch 7/50\n",
      "45/45 [==============================] - 0s 4ms/step - loss: 0.6135 - accuracy: 0.8457\n",
      "Epoch 8/50\n",
      "45/45 [==============================] - 0s 4ms/step - loss: 0.6173 - accuracy: 0.8303\n",
      "Epoch 9/50\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6123 - accuracy: 0.8457\n",
      "Epoch 10/50\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6120 - accuracy: 0.8471\n",
      "Epoch 11/50\n",
      "45/45 [==============================] - 0s 4ms/step - loss: 0.6113 - accuracy: 0.8471\n",
      "Epoch 12/50\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6117 - accuracy: 0.8457\n",
      "Epoch 13/50\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6124 - accuracy: 0.8471\n",
      "Epoch 14/50\n",
      "45/45 [==============================] - 0s 4ms/step - loss: 0.6110 - accuracy: 0.8513\n",
      "Epoch 15/50\n",
      "45/45 [==============================] - 0s 4ms/step - loss: 0.6146 - accuracy: 0.8471\n",
      "Epoch 16/50\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6096 - accuracy: 0.8513\n",
      "Epoch 17/50\n",
      "45/45 [==============================] - 0s 4ms/step - loss: 0.6090 - accuracy: 0.8555: 0s - loss: 0.6075 - accuracy: \n",
      "Epoch 18/50\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6113 - accuracy: 0.8499\n",
      "Epoch 19/50\n",
      "45/45 [==============================] - 0s 4ms/step - loss: 0.6096 - accuracy: 0.8513\n",
      "Epoch 20/50\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6075 - accuracy: 0.8569\n",
      "Epoch 21/50\n",
      "45/45 [==============================] - 0s 4ms/step - loss: 0.6066 - accuracy: 0.8583\n",
      "Epoch 22/50\n",
      "45/45 [==============================] - 0s 4ms/step - loss: 0.6075 - accuracy: 0.8555: 0s - loss: 0.6091 - accuracy: \n",
      "Epoch 23/50\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 0.6057 - accuracy: 0.8612\n",
      "Epoch 24/50\n",
      "45/45 [==============================] - 0s 4ms/step - loss: 0.6062 - accuracy: 0.8583\n",
      "Epoch 25/50\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6080 - accuracy: 0.8541\n",
      "Epoch 26/50\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6062 - accuracy: 0.8597\n",
      "Epoch 27/50\n",
      "45/45 [==============================] - 0s 4ms/step - loss: 0.6054 - accuracy: 0.8597\n",
      "Epoch 28/50\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 0.6094 - accuracy: 0.8555\n",
      "Epoch 29/50\n",
      "45/45 [==============================] - 0s 4ms/step - loss: 0.6071 - accuracy: 0.8583\n",
      "Epoch 30/50\n",
      "45/45 [==============================] - 0s 4ms/step - loss: 0.6061 - accuracy: 0.8612\n",
      "Epoch 31/50\n",
      "45/45 [==============================] - 0s 4ms/step - loss: 0.6072 - accuracy: 0.8583\n",
      "Epoch 32/50\n",
      "45/45 [==============================] - 0s 4ms/step - loss: 0.6076 - accuracy: 0.8555\n",
      "Epoch 33/50\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6067 - accuracy: 0.8569\n",
      "Epoch 34/50\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6050 - accuracy: 0.8612\n",
      "Epoch 35/50\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6060 - accuracy: 0.8597\n",
      "Epoch 36/50\n",
      "45/45 [==============================] - 0s 4ms/step - loss: 0.6065 - accuracy: 0.8583\n",
      "Epoch 37/50\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6053 - accuracy: 0.8597\n",
      "Epoch 38/50\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6062 - accuracy: 0.8583\n",
      "Epoch 39/50\n",
      "45/45 [==============================] - 0s 4ms/step - loss: 0.6050 - accuracy: 0.8612\n",
      "Epoch 40/50\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6068 - accuracy: 0.8583\n",
      "Epoch 41/50\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6056 - accuracy: 0.8597\n",
      "Epoch 42/50\n",
      "45/45 [==============================] - 0s 4ms/step - loss: 0.6064 - accuracy: 0.8597\n",
      "Epoch 43/50\n",
      "45/45 [==============================] - 0s 4ms/step - loss: 0.6051 - accuracy: 0.8612\n",
      "Epoch 44/50\n",
      "45/45 [==============================] - 0s 4ms/step - loss: 0.6065 - accuracy: 0.8569\n",
      "Epoch 45/50\n",
      "45/45 [==============================] - 0s 4ms/step - loss: 0.6050 - accuracy: 0.8612\n",
      "Epoch 46/50\n",
      "45/45 [==============================] - 0s 4ms/step - loss: 0.6054 - accuracy: 0.8597\n",
      "Epoch 47/50\n",
      "45/45 [==============================] - 0s 4ms/step - loss: 0.6051 - accuracy: 0.8626\n",
      "Epoch 48/50\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6053 - accuracy: 0.8612\n",
      "Epoch 49/50\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.6055 - accuracy: 0.8612\n",
      "Epoch 50/50\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6057 - accuracy: 0.8612\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e82bf47340>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "\n",
    "init_he = tf.keras.initializers.HeNormal()\n",
    "init_x = tf.keras.initializers.GlorotNormal()\n",
    "\n",
    "#model.add(tf.keras.layers.InputLayer(input_shape = (571, 8)))\n",
    "model.add(tf.keras.layers.Dense(256, activation = \"relu\", kernel_initializer = init_he))\n",
    "model.add(tf.keras.layers.Dense(128, activation = \"relu\", kernel_initializer = init_he))\n",
    "model.add(tf.keras.layers.Dense(64, activation = \"relu\", kernel_initializer = init_he))\n",
    "model.add(tf.keras.layers.Dense(64, activation = \"relu\", kernel_initializer = init_he))\n",
    "model.add(tf.keras.layers.Dense(64, activation = \"relu\", kernel_initializer = init_he))\n",
    "model.add(tf.keras.layers.Dense(1, activation = \"sigmoid\", kernel_initializer = init_x))\n",
    "\n",
    "cost = tf.keras.losses.BinaryCrossentropy(from_logits = True)\n",
    "opt = tf.keras.optimizers.RMSprop(learning_rate = 0.001)\n",
    "\n",
    "\n",
    "model.compile(optimizer = opt, loss = cost, metrics = [\"accuracy\"])\n",
    "\n",
    "model.fit(X, Y, batch_size = 16, epochs = 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "c01a29f6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 0s - loss: 0.6072 - accuracy: 0.8583\n",
      "6/6 - 0s - loss: 0.6144 - accuracy: 0.8427\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6144161224365234, 0.8426966071128845]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X, Y, verbose = 2)\n",
    "model.evaluate(X_dev, Y_dev, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "c8fbc40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_csv(filename, predictions, passID):\n",
    "    '''\n",
    "    Writes to csv two columns of passangerID and whether they survived\n",
    "    \n",
    "    filename: Name of csv to write to\n",
    "    prediction: npArray of prediction\n",
    "    passID: npArray containing passIDs\n",
    "    '''\n",
    "    new_df = pd.DataFrame({\"PassengerID\": passID, \"Survived\":predictions}, index = [0] * len(passID))\n",
    "    \n",
    "    new_df.to_csv(filename + \".csv\", index = False)\n",
    "    \n",
    "pred = model.predict(X_test).round().astype(int).reshape(-1,)\n",
    "\n",
    "passID = test.index.to_numpy().astype(int)\n",
    "\n",
    "write_to_csv(\"sub1_rms\", pred, passID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9bae366d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([ 892,  893,  894,  895,  896,  897,  898,  899,  900,  901,\n",
       "            ...\n",
       "            1300, 1301, 1302, 1303, 1304, 1305, 1306, 1307, 1308, 1309],\n",
       "           dtype='int64', name='PassengerId', length=418)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.index"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
