{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5223fcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5c5a2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting index for easier usage\n",
    "train = pd.read_csv(\"train.csv\").set_index(\"PassengerId\")\n",
    "test = pd.read_csv(\"test.csv\").set_index(\"PassengerId\")\n",
    "\n",
    "train = train.drop(\"Cabin\", axis = 1)\n",
    "test = test.drop(\"Cabin\", axis = 1)\n",
    "\n",
    "\n",
    "#Dropping cabin column as a whole and also removing rows that are missing an Age value\n",
    "# train = train[train.Age.notnull()].drop(\"Cabin\", axis = 1)\n",
    "# test = test[test.Age.notnull()].drop(\"Cabin\", axis = 1)\n",
    "\n",
    "#Filling the two missing values in Embarked that I found on google\n",
    "train.Embarked = train.Embarked.fillna(\"S\")\n",
    "\n",
    "#Removing ticket prefix,replacing the special value of ticket and then converting all to floats\n",
    "train = train[train.Ticket != \"LINE\"]\n",
    "test = test[test.Ticket != \"LINE\"]\n",
    "train.Ticket = train.Ticket.map(lambda t : t.split()[-1]).astype(\"float\")\n",
    "test.Ticket = test.Ticket.map(lambda t : t.split()[-1]).astype(\"float\")\n",
    "\n",
    "#Replacing each value of Embarked with a respective integer\n",
    "# train.Embarked = train.Embarked.replace(\"S\", 1).replace(\"Q\", 2).replace(\"C\", 3)\n",
    "# test.Embarked = test.Embarked.replace(\"S\", 1).replace(\"Q\", 2).replace(\"C\", 3)\n",
    "\n",
    "#Same with sex\n",
    "train.Sex = train.Sex.replace(\"male\", 1).replace(\"female\", 0)\n",
    "test.Sex = test.Sex.replace(\"male\", 1).replace(\"female\", 0)\n",
    "\n",
    "dummies = pd.get_dummies(train.Pclass, prefix = \"class\")\n",
    "dummies_embark = pd.get_dummies(train.Embarked, prefix = \"loc\")\n",
    "train = pd.concat([train, dummies, dummies_embark], axis = 1).drop(\"Pclass\", axis = 1).drop(\"Embarked\", axis = 1)\n",
    "\n",
    "dummies = pd.get_dummies(test.Pclass, prefix = \"class\")\n",
    "dummies_embark = pd.get_dummies(test.Embarked, prefix = \"loc\")\n",
    "test = pd.concat([test, dummies, dummies_embark], axis = 1).drop(\"Pclass\", axis = 1).drop(\"Embarked\", axis = 1)\n",
    "\n",
    "#Replacing titles with dummy\n",
    "def get_title(name):\n",
    "    if '.' in name:\n",
    "        return name.split(',')[1].split('.')[0].strip()\n",
    "    else:\n",
    "        return 'Unknown'\n",
    "\n",
    "def replace_titles(x):\n",
    "    title = x['Title']\n",
    "    if title in ['Capt', 'Col', 'Don', 'Jonkheer', 'Major', 'Rev', 'Sir']:\n",
    "        return 'Mr'\n",
    "    elif title in ['the Countess', 'Mme', 'Lady']:\n",
    "        return 'Mrs'\n",
    "    elif title in ['Mlle', 'Ms']:\n",
    "        return 'Miss'\n",
    "    elif title =='Dr':\n",
    "        if x['Sex']=='male':\n",
    "            return 'Mr'\n",
    "        else:\n",
    "            return 'Mrs'\n",
    "    else:\n",
    "        return title\n",
    "    \n",
    "train['Title'] = train['Name'].map(lambda x: get_title(x))\n",
    "train['Title'] = train.apply(replace_titles, axis=1)\n",
    "\n",
    "test['Title'] = test['Name'].map(lambda x: get_title(x))\n",
    "test['Title'] = test.apply(replace_titles, axis=1)\n",
    "\n",
    "dummies = pd.get_dummies(train.Title)\n",
    "test_dummies = pd.get_dummies(test.Title)\n",
    "\n",
    "train = pd.concat([train, dummies], axis = 1).drop(\"Name\", axis = 1).drop(\"Title\", axis = 1)\n",
    "test = pd.concat([test, test_dummies], axis =1).drop(\"Name\", axis = 1).drop(\"Title\", axis = 1)\n",
    "\n",
    "full = pd.concat([train, test])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "ticket = full.Ticket.to_numpy().reshape(-1, 1)\n",
    "fare = full.Fare.to_numpy().reshape(-1, 1)\n",
    "age = full.Age.to_numpy().reshape(-1, 1)\n",
    "\n",
    "full.Ticket = scaler.fit_transform(ticket)\n",
    "full.Fare = scaler.fit_transform(fare)\n",
    "full.Age = scaler.fit_transform(age)\n",
    "\n",
    "#Dealing with missing ages\n",
    "\n",
    "imputer = IterativeImputer()\n",
    "features = [\"Age\", \"Pclass\"]\n",
    "\n",
    "full = pd.DataFrame(imputer.fit_transform(full), index = full.index, columns = full.columns)\n",
    "\n",
    "#Iterative imputation of train Age category\n",
    "train = full[:len(train)]\n",
    "test = full[len(train):]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61829f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Ticket\", \"Fare\", \"class_1\", \"class_2\", \"class_3\", \"loc_C\", \"loc_Q\", \"loc_S\", \"Master\", \"Miss\", \"Mr\", \"Mrs\"]\n",
    "\n",
    "#Converting the features to numpy arrays\n",
    "X = train[features].to_numpy()\n",
    "X_test = test[features].to_numpy().transpose()\n",
    "\n",
    "X_test = X_test.T\n",
    "\n",
    "#Same with Y\n",
    "Y = train[\"Survived\"].to_numpy()\n",
    "Y = Y.reshape((Y.shape[0], 1))\n",
    "\n",
    "\n",
    "#Splitting into 80-20 train dev split\n",
    "#TODO: MANUALLY SPLIT, MAKE THE AVG AGE DISTRIBUTION BE IN \n",
    "X, X_dev, Y, Y_dev = train_test_split(X, Y, test_size = 0.25)\n",
    "\n",
    "\n",
    "#Transposing all so they have correct dimentions\n",
    "X = X.astype(\"float32\")\n",
    "X_dev = X_dev.astype(\"float32\")\n",
    "Y = Y.astype(\"float32\")\n",
    "Y_dev = Y_dev.astype(\"float32\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c9bad0fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "111/111 [==============================] - 0s 592us/step - loss: 0.6430 - accuracy: 0.7756\n",
      "Epoch 2/50\n",
      "111/111 [==============================] - 0s 512us/step - loss: 0.6246 - accuracy: 0.8230\n",
      "Epoch 3/50\n",
      "111/111 [==============================] - 0s 575us/step - loss: 0.6199 - accuracy: 0.8230\n",
      "Epoch 4/50\n",
      "111/111 [==============================] - 0s 566us/step - loss: 0.6169 - accuracy: 0.8343\n",
      "Epoch 5/50\n",
      "111/111 [==============================] - 0s 584us/step - loss: 0.6129 - accuracy: 0.8467\n",
      "Epoch 6/50\n",
      "111/111 [==============================] - 0s 629us/step - loss: 0.6118 - accuracy: 0.8444\n",
      "Epoch 7/50\n",
      "111/111 [==============================] - 0s 593us/step - loss: 0.6109 - accuracy: 0.8478\n",
      "Epoch 8/50\n",
      "111/111 [==============================] - 0s 575us/step - loss: 0.6092 - accuracy: 0.8489\n",
      "Epoch 9/50\n",
      "111/111 [==============================] - 0s 657us/step - loss: 0.6092 - accuracy: 0.8501\n",
      "Epoch 10/50\n",
      "111/111 [==============================] - 0s 525us/step - loss: 0.6132 - accuracy: 0.8410\n",
      "Epoch 11/50\n",
      "111/111 [==============================] - 0s 535us/step - loss: 0.6093 - accuracy: 0.8444\n",
      "Epoch 12/50\n",
      "111/111 [==============================] - 0s 557us/step - loss: 0.6075 - accuracy: 0.8523\n",
      "Epoch 13/50\n",
      "111/111 [==============================] - 0s 595us/step - loss: 0.6062 - accuracy: 0.8591\n",
      "Epoch 14/50\n",
      "111/111 [==============================] - 0s 575us/step - loss: 0.6089 - accuracy: 0.8478\n",
      "Epoch 15/50\n",
      "111/111 [==============================] - 0s 584us/step - loss: 0.6116 - accuracy: 0.8433\n",
      "Epoch 16/50\n",
      "111/111 [==============================] - 0s 554us/step - loss: 0.6081 - accuracy: 0.8546\n",
      "Epoch 17/50\n",
      "111/111 [==============================] - 0s 585us/step - loss: 0.6082 - accuracy: 0.8534\n",
      "Epoch 18/50\n",
      "111/111 [==============================] - 0s 533us/step - loss: 0.6085 - accuracy: 0.8523\n",
      "Epoch 19/50\n",
      "111/111 [==============================] - 0s 557us/step - loss: 0.6076 - accuracy: 0.8557\n",
      "Epoch 20/50\n",
      "111/111 [==============================] - 0s 557us/step - loss: 0.6080 - accuracy: 0.8534\n",
      "Epoch 21/50\n",
      "111/111 [==============================] - 0s 602us/step - loss: 0.6065 - accuracy: 0.8568\n",
      "Epoch 22/50\n",
      "111/111 [==============================] - 0s 566us/step - loss: 0.6050 - accuracy: 0.8591\n",
      "Epoch 23/50\n",
      "111/111 [==============================] - 0s 557us/step - loss: 0.6081 - accuracy: 0.8512\n",
      "Epoch 24/50\n",
      "111/111 [==============================] - 0s 584us/step - loss: 0.6074 - accuracy: 0.8546\n",
      "Epoch 25/50\n",
      "111/111 [==============================] - 0s 574us/step - loss: 0.6050 - accuracy: 0.8591\n",
      "Epoch 26/50\n",
      "111/111 [==============================] - 0s 568us/step - loss: 0.6072 - accuracy: 0.8557\n",
      "Epoch 27/50\n",
      "111/111 [==============================] - 0s 528us/step - loss: 0.6054 - accuracy: 0.8602\n",
      "Epoch 28/50\n",
      "111/111 [==============================] - 0s 581us/step - loss: 0.6062 - accuracy: 0.8579\n",
      "Epoch 29/50\n",
      "111/111 [==============================] - 0s 585us/step - loss: 0.6048 - accuracy: 0.8591\n",
      "Epoch 30/50\n",
      "111/111 [==============================] - 0s 568us/step - loss: 0.6035 - accuracy: 0.8625\n",
      "Epoch 31/50\n",
      "111/111 [==============================] - 0s 575us/step - loss: 0.6022 - accuracy: 0.8647\n",
      "Epoch 32/50\n",
      "111/111 [==============================] - 0s 544us/step - loss: 0.6054 - accuracy: 0.8568\n",
      "Epoch 33/50\n",
      "111/111 [==============================] - 0s 557us/step - loss: 0.6057 - accuracy: 0.8557\n",
      "Epoch 34/50\n",
      "111/111 [==============================] - 0s 549us/step - loss: 0.6039 - accuracy: 0.8602\n",
      "Epoch 35/50\n",
      "111/111 [==============================] - 0s 509us/step - loss: 0.6042 - accuracy: 0.8591\n",
      "Epoch 36/50\n",
      "111/111 [==============================] - 0s 559us/step - loss: 0.6039 - accuracy: 0.8602\n",
      "Epoch 37/50\n",
      "111/111 [==============================] - 0s 621us/step - loss: 0.6047 - accuracy: 0.8591\n",
      "Epoch 38/50\n",
      "111/111 [==============================] - 0s 587us/step - loss: 0.6047 - accuracy: 0.8579\n",
      "Epoch 39/50\n",
      "111/111 [==============================] - 0s 584us/step - loss: 0.6056 - accuracy: 0.8534\n",
      "Epoch 40/50\n",
      "111/111 [==============================] - 0s 548us/step - loss: 0.6048 - accuracy: 0.8579\n",
      "Epoch 41/50\n",
      "111/111 [==============================] - 0s 566us/step - loss: 0.6039 - accuracy: 0.8602\n",
      "Epoch 42/50\n",
      "111/111 [==============================] - 0s 548us/step - loss: 0.6035 - accuracy: 0.8602\n",
      "Epoch 43/50\n",
      "111/111 [==============================] - 0s 545us/step - loss: 0.6043 - accuracy: 0.8591\n",
      "Epoch 44/50\n",
      "111/111 [==============================] - 0s 575us/step - loss: 0.6035 - accuracy: 0.8613\n",
      "Epoch 45/50\n",
      "111/111 [==============================] - 0s 560us/step - loss: 0.6050 - accuracy: 0.8602\n",
      "Epoch 46/50\n",
      "111/111 [==============================] - 0s 663us/step - loss: 0.6039 - accuracy: 0.8602\n",
      "Epoch 47/50\n",
      "111/111 [==============================] - 0s 575us/step - loss: 0.6035 - accuracy: 0.8613\n",
      "Epoch 48/50\n",
      "111/111 [==============================] - 0s 574us/step - loss: 0.6040 - accuracy: 0.8602\n",
      "Epoch 49/50\n",
      "111/111 [==============================] - 0s 566us/step - loss: 0.6043 - accuracy: 0.8591\n",
      "Epoch 50/50\n",
      "111/111 [==============================] - 0s 604us/step - loss: 0.6040 - accuracy: 0.8602\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22229cb3a60>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "\n",
    "init_he = tf.keras.initializers.HeNormal()\n",
    "init_x = tf.keras.initializers.GlorotNormal()\n",
    "\n",
    "model.add(tf.keras.layers.Dense(128, activation = \"relu\", kernel_initializer = init_he))\n",
    "model.add(tf.keras.layers.Dropout(rate = 0.25))\n",
    "model.add(tf.keras.layers.Dense(1, activation = \"sigmoid\", kernel_initializer = init_x))\n",
    "\n",
    "cost = tf.keras.losses.BinaryCrossentropy(from_logits = True)\n",
    "opt = tf.keras.optimizers.RMSprop(learning_rate = 0.015)\n",
    "\n",
    "\n",
    "model.compile(optimizer = opt, loss = cost, metrics = [\"accuracy\"])\n",
    "\n",
    "model.fit(X, Y, batch_size = 8, epochs = 50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47228c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 512us/step - loss: 0.6001 - accuracy: 0.8703\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6000521183013916, 0.8703494668006897]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X, Y)\n",
    "#model.evaluate(X_dev, Y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c8fbc40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_csv(filename, predictions, passID):\n",
    "\n",
    "    new_df = pd.DataFrame({\"PassengerID\": passID, \"Survived\":predictions}, index = [0] * len(passID))\n",
    "    \n",
    "    new_df.to_csv(filename + \".csv\", index = False)\n",
    "    \n",
    "pred = model.predict(X_test).round().astype(int).reshape(-1,)\n",
    "\n",
    "passID = test.index.to_numpy().astype(int)\n",
    "\n",
    "write_to_csv(\"dropout0.25_50iter\", pred, passID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9bae366d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([ 892,  893,  894,  895,  896,  897,  898,  899,  900,  901,\n",
       "            ...\n",
       "            1300, 1301, 1302, 1303, 1304, 1305, 1306, 1307, 1308, 1309],\n",
       "           dtype='int64', name='PassengerId', length=418)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.index"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
